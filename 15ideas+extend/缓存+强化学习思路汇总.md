强化学习论文思路归纳：

## 1、RL-cache

通过考虑三个features： object size， request recency和 request frequency。与启发式的方法不同，这个方法可以同时考虑三种feature中的8个参数。设计神经网络近似policy function 使得return最大，即命中率最大。

## 2、DeepCache:

 To keep it simple, we drive this paper with a goal to increase the number of cache hits. 创造一种自适应的缓存机制，由请求流量的变化，预测未来特征，提前将popularity高的对象预取，提高缓存命中率。了解对象的流行程度，防止替换出流行的chunk，减少网络抖动问题。

作者将popularity的预测看作seq2seq的结构，整体由popularity prediction预测框架和DeepCache的缓存框架构成。

## 3、Viewport-Aware Deep Reinforcement

现有的解决方案假定已知的流行度，但情况可能并不总是如此

